{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Training GPT-2 for Text Generation and Intent Recognition using Multi-Model Learning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "232a0207d8c12cf2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Imports and Initial Setup**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8cb6c9628024965"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# If Colab\n",
    "import os\n",
    "os.chdir('/content/drive/Othercomputers/AKATSUKI-PC/PycharmProjects/chatopotamus')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T21:39:17.506274700Z",
     "start_time": "2023-11-22T21:39:17.502087500Z"
    }
   },
   "id": "886de793b95694fc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:19.962091500Z",
     "start_time": "2023-11-23T06:18:05.528570800Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import joblib\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from src.training import gpt_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c19477c69ff5c57b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# If Local Interpreter\n",
    "os.chdir('C:\\\\Users\\\\thory\\\\PycharmProjects\\\\chatopotamus')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:31.575532100Z",
     "start_time": "2023-11-23T06:18:31.556869300Z"
    }
   },
   "id": "17661f2166b661c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Path Constants**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f5f01a5e0d687f2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "DATA_PATH = 'resources/gpt/data'\n",
    "ORDERS_PATH = os.path.join(DATA_PATH, 'orders.txt')\n",
    "ENQUIRY_PATH = os.path.join(DATA_PATH, 'enquiry.txt')\n",
    "COMPLAINS_PATH = os.path.join(DATA_PATH, 'complains.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:31.622287800Z",
     "start_time": "2023-11-23T06:18:31.574533200Z"
    }
   },
   "id": "5c997b8629569d33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Convert into Sequences**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97232d0e81e9ecaa"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "final_sequence_order, intent_order  = gpt_trainer.file_to_sequences(ORDERS_PATH, intent='order')\n",
    "final_sequence_enquiry, intent_enquiry = gpt_trainer.file_to_sequences(ENQUIRY_PATH, intent='enquiry')\n",
    "final_sequence_complain, intent_complain = gpt_trainer.file_to_sequences(COMPLAINS_PATH, intent='complain')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:31.699705800Z",
     "start_time": "2023-11-23T06:18:31.604392100Z"
    }
   },
   "id": "39dcbcbc894ed03"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "final_sequences = final_sequence_complain + final_sequence_enquiry + final_sequence_order\n",
    "final_intents = intent_complain+intent_enquiry+intent_order"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:31.731563200Z",
     "start_time": "2023-11-23T06:18:31.694448400Z"
    }
   },
   "id": "523b76b4f189caae"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(\"customer: my hot chocolate was too hot to drink system: that's not good would you like us to remake it at a cooler temperature or something else? customer: a cooler remake would be great system: you got it! we'll make sure your hot chocolate is at a comfortable temperature anything else? customer: no thank you system: perfect we're on it your hot chocolate will be ready shortly thanks for letting us correct it! customer: the grilled cheese i ordered was too dry system: we apologize for that would you like a new one maybe with extra butter or a different sandwich?\",\n 'complain')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sequences[89], final_intents[89]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:31.809212100Z",
     "start_time": "2023-11-23T06:18:31.708707600Z"
    }
   },
   "id": "d190b4c090d677ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Tokenize**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b7f1c7aca3f1bc8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_inputs = tokenizer(final_sequences, max_length=150, truncation=True, padding=True, return_tensors=\"tf\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:34.793368700Z",
     "start_time": "2023-11-23T06:18:31.745223200Z"
    }
   },
   "id": "b288b2c3602e1cf"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': <tf.Tensor: shape=(1083, 150), dtype=int32, numpy=\narray([[23144,   263,    25, ..., 50256, 50256, 50256],\n       [23144,   263,    25, ...,   318,   262,   691],\n       [23144,   263,    25, ..., 50256, 50256, 50256],\n       ...,\n       [23144,   263,    25, ...,    30,  1080,    25],\n       [23144,   263,    25, ...,   257,   467,     0],\n       [23144,   263,    25, ..., 50256, 50256, 50256]])>, 'attention_mask': <tf.Tensor: shape=(1083, 150), dtype=int32, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 0, 0, 0]])>}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:34.912746300Z",
     "start_time": "2023-11-23T06:18:34.799370600Z"
    }
   },
   "id": "bb4f663c4cf2b9a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Preprocessing**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beb1ff3dd472b147"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 140), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 140), dtype=tf.int32, name=None)}, {'input_ids': TensorSpec(shape=(None, 140), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 140), dtype=tf.int32, name=None)})>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_data_gen = gpt_trainer.preprocess_for_generation(tokenized_inputs)\n",
    "prepped_data_gen"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:53.775828Z",
     "start_time": "2023-11-23T06:18:53.460554800Z"
    }
   },
   "id": "e11d5412523cd6aa"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 150), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 150), dtype=tf.int32, name=None)}, TensorSpec(shape=(None, 3), dtype=tf.float32, name=None))>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_data_intent = gpt_trainer.preprocessing_for_intent(tokenized_inputs, final_intents)\n",
    "prepped_data_intent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:18:55.215640900Z",
     "start_time": "2023-11-23T06:18:55.105648900Z"
    }
   },
   "id": "d0d50d16b16318f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train-Test Split**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8f55236b9e79102"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "gen_splits = []\n",
    "intent_splits = []\n",
    "for prepped_data, type_ in zip([prepped_data_intent, prepped_data_gen], [gen_splits, intent_splits]):\n",
    "    total_size = 0\n",
    "    for _ in prepped_data:\n",
    "        total_size += 1\n",
    "    \n",
    "    train_size = int(0.6 * total_size)\n",
    "    val_size = int(0.2 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "    \n",
    "    type_ += [prepped_data.take(train_size), prepped_data.skip(train_size).take(val_size), prepped_data.skip(train_size+val_size)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T06:34:02.521691900Z",
     "start_time": "2023-11-23T06:34:02.410897300Z"
    }
   },
   "id": "5ae04c583a07d668"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "339923921e09967d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Saving/Loading**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e76a4fa8f46f2c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpt_trainer.save_file('resources/gpt/data/tokenized_inputs.pkl', tokenized_inputs)\n",
    "prepped_data_gen.save('resources/gpt/prepped_data_gen')\n",
    "prepped_data_intent.save('resources/gpt/prepped_data_intent')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17feae0c52c6766f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('resources/gpt/data/tokenized_inputs.pkl', 'rb') as f:\n",
    "    tokenized_inputs = joblib.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5282737de0ef373"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
